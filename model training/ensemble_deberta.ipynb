{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "from scipy.special import softmax\n",
    "import evaluate\n",
    "from datasets import Dataset, features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package            Version\n",
      "------------------ -----------\n",
      "accelerate         0.29.3\n",
      "aiohttp            3.9.5\n",
      "aiosignal          1.3.1\n",
      "appnope            0.1.4\n",
      "asttokens          2.4.1\n",
      "attrs              23.2.0\n",
      "certifi            2024.2.2\n",
      "charset-normalizer 3.3.2\n",
      "comm               0.2.2\n",
      "datasets           2.18.0\n",
      "debugpy            1.8.1\n",
      "decorator          5.1.1\n",
      "dill               0.3.8\n",
      "evaluate           0.4.1\n",
      "executing          2.0.1\n",
      "filelock           3.13.4\n",
      "frozenlist         1.4.1\n",
      "fsspec             2024.2.0\n",
      "huggingface-hub    0.22.2\n",
      "idna               3.7\n",
      "ipykernel          6.29.4\n",
      "ipython            8.23.0\n",
      "ipywidgets         8.1.2\n",
      "jedi               0.19.1\n",
      "Jinja2             3.1.3\n",
      "joblib             1.4.0\n",
      "jupyter_client     8.6.1\n",
      "jupyter_core       5.7.2\n",
      "jupyterlab_widgets 3.0.10\n",
      "kagglehub          0.2.3\n",
      "MarkupSafe         2.1.5\n",
      "matplotlib-inline  0.1.7\n",
      "mpmath             1.3.0\n",
      "multidict          6.0.5\n",
      "multiprocess       0.70.16\n",
      "nest-asyncio       1.6.0\n",
      "networkx           3.3\n",
      "numpy              1.26.4\n",
      "packaging          24.0\n",
      "pandas             2.2.2\n",
      "parso              0.8.4\n",
      "pexpect            4.9.0\n",
      "pip                24.0\n",
      "platformdirs       4.2.0\n",
      "prompt-toolkit     3.0.43\n",
      "psutil             5.9.8\n",
      "ptyprocess         0.7.0\n",
      "pure-eval          0.2.2\n",
      "pyarrow            15.0.2\n",
      "pyarrow-hotfix     0.6\n",
      "Pygments           2.17.2\n",
      "python-dateutil    2.9.0.post0\n",
      "pytz               2024.1\n",
      "PyYAML             6.0.1\n",
      "pyzmq              26.0.0\n",
      "regex              2024.4.16\n",
      "requests           2.31.0\n",
      "responses          0.18.0\n",
      "safetensors        0.4.3\n",
      "scikit-learn       1.4.2\n",
      "scipy              1.13.0\n",
      "seqeval            1.2.2\n",
      "six                1.16.0\n",
      "stack-data         0.6.3\n",
      "sympy              1.12\n",
      "threadpoolctl      3.4.0\n",
      "tokenizers         0.15.2\n",
      "torch              2.2.2\n",
      "tornado            6.4\n",
      "tqdm               4.66.2\n",
      "traitlets          5.14.2\n",
      "transformers       4.39.3\n",
      "typing_extensions  4.11.0\n",
      "tzdata             2024.1\n",
      "urllib3            2.2.1\n",
      "wcwidth            0.2.13\n",
      "widgetsnbextension 4.0.10\n",
      "xxhash             3.4.1\n",
      "yarl               1.9.4\n"
     ]
    }
   ],
   "source": [
    "! pip3 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the kaggle provided data\n",
    "* Loading jsons\n",
    "* Downsampling negative samples of the data\n",
    "* Defining and applying tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datapoints:  9162\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open(\"kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n",
    "\n",
    "# convert csv to json and append to data\n",
    "# mistral_df = pd.read_csv(\"kaggle/input/pii-detection-removal-from-educational-data/100_gen_data.csv\")\n",
    "# mistral_df.head()\n",
    "# for i in range(len(mistral_df)):\n",
    "#     data.append({\"tokens\": mistral_df['tokenized response'][i], \"labels\": mistral_df['labels'][i]})\n",
    "\n",
    "mistral_data = json.load(open(\"kaggle/input/pii-detection-removal-from-educational-data/mistral_data.json\"))\n",
    "for d in mistral_data:\n",
    "    data.append(d)\n",
    "\n",
    "# # downsampling of negative examples\n",
    "# # p=[] # positive samples (contain relevant labels)\n",
    "# # n=[] # negative samples (presumably contain entities that are possibly wrongly classified as entity)\n",
    "# # for d in data:\n",
    "# #     if any(np.array(d[\"labels\"]) != \"O\"): p.append(d)\n",
    "# #     else: n.append(d)\n",
    "print(\"original datapoints: \", len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B-EMAIL', 1: 'B-ID_NUM', 2: 'B-NAME_STUDENT', 3: 'B-PHONE_NUM', 4: 'B-STREET_ADDRESS', 5: 'B-URL_PERSONAL', 6: 'B-USERNAME', 7: 'I-ID_NUM', 8: 'I-NAME_STUDENT', 9: 'I-PHONE_NUM', 10: 'I-STREET_ADDRESS', 11: 'I-URL_PERSONAL', 12: 'O'}\n"
     ]
    }
   ],
   "source": [
    "all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n",
    "label2id = {l: i for i,l in enumerate(all_labels)}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "target = [\n",
    "    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n",
    "    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n",
    "    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n",
    "]\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id, max_length):\n",
    "\n",
    "    # rebuild text from tokens\n",
    "    text = []\n",
    "    labels = []\n",
    "\n",
    "    for t, l, ws in zip(\n",
    "        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n",
    "    ):\n",
    "        text.append(t)\n",
    "        labels.extend([l] * len(t))\n",
    "\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    # actual tokenization\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    text = \"\".join(text)\n",
    "    token_labels = []\n",
    "\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # CLS token\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # case when token starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800e99f3199142f483f43e26c875e0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=3):   0%|          | 0/9162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the data utilizing deberta tokenizer\n",
    "TRAIN_MODEL_PATH = \"microsoft/deberta-base\"\n",
    "TRAIN_MAX_LENGTH = 1024\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRAIN_MODEL_PATH)\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"full_text\": [x[\"full_text\"] for x in data],\n",
    "    \"document\": [str(x[\"document\"]) for x in data],\n",
    "    \"tokens\": [x[\"tokens\"] for x in data],\n",
    "    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "    \"provided_labels\": [x[\"labels\"] for x in data],\n",
    "})\n",
    "\n",
    "ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": TRAIN_MAX_LENGTH}, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsample(df, percent):\n",
    "#     df = df.copy()\n",
    "\n",
    "#     df['is_labels'] = df['provided_labels'].apply(lambda labels: any(label != \"O\" for label in labels))\n",
    "#     true_samples = df[df['is_labels'] == True]\n",
    "#     false_samples = df[df['is_labels'] == False]\n",
    "\n",
    "#     downsampled_false_samples = false_samples.sample(frac=percent, random_state=42)\n",
    "\n",
    "\n",
    "#     return pd.concat([true_samples, downsampled_false_samples])\n",
    "\n",
    "# # Downsample the negative samples of the dataset\n",
    "# df_train = pd.DataFrame(ds)\n",
    "# df_train = downsample(df_train, 0.2)\n",
    "# df_train = df_train.drop(columns=['is_labels'])\n",
    "\n",
    "# ds = Dataset.from_pandas(df_train)\n",
    "# # Splitting the dataset into training and validation sets for performance evaluation\n",
    "# ds = ds.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation of model\n",
    "* Defining metrics (precision, recall, and f5-score)\n",
    "* Training model\n",
    "* Evaluating on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score\n",
    "\n",
    "def metrics(p, all_labels):\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "            [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(preds, labels)\n",
    "        ]\n",
    "    true_labels = [\n",
    "            [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(preds, labels)\n",
    "        ]\n",
    "\n",
    "    precision = precision_score(true_labels, true_predictions, average='micro')\n",
    "    recall = recall_score(true_labels, true_predictions, average='micro')\n",
    "\n",
    "    f5_score = (1 + 5 ** 2) * (precision * recall) / (5 ** 2 * precision + recall)\n",
    "\n",
    "    results = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f5\": f5_score\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to MPS device.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    TRAIN_MODEL_PATH,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "# mps GPU acceleration for training \n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    model.to(mps_device)\n",
    "    print(\"Model moved to MPS device.\")\n",
    "elif torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print(\"Model moved to CUDA device.\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU.\")\n",
    "\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.shuffle(seed=42).select(range(100))\n",
    "\n",
    "num_folds = 5\n",
    "fold_size = len(dataset) // num_folds\n",
    "\n",
    "folds = []\n",
    "for i in range(num_folds):\n",
    "    # Calculate start and end indices\n",
    "    start = i * fold_size\n",
    "    end = start + fold_size if i < num_folds - 1 else len(dataset)\n",
    "\n",
    "    # Select data for the fold\n",
    "    fold = dataset.select(range(start, end))\n",
    "    folds.append(fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/antoniorevilla/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244ef37c7b3743f4a8bf2c67fe266275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 30.1074, 'train_samples_per_second': 1.993, 'train_steps_per_second': 0.199, 'train_loss': 1.9978763262430828, 'epoch': 2.4}\n",
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129c913eed0e4278a950e1f66f69bb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 153.503, 'train_samples_per_second': 0.391, 'train_steps_per_second': 0.039, 'train_loss': 2.0649898846944175, 'epoch': 2.4}\n",
      "Training fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c724e66cfa4f7393407ca91c0d2bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 27.7956, 'train_samples_per_second': 2.159, 'train_steps_per_second': 0.216, 'train_loss': 2.0458219846089682, 'epoch': 2.4}\n",
      "Training fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d23b8cc29341f3bb0570d8943c6ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 26.3024, 'train_samples_per_second': 2.281, 'train_steps_per_second': 0.228, 'train_loss': 2.051828225453695, 'epoch': 2.4}\n",
      "Training fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d2886a63c54fa39db934a2eb2177cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 28.9089, 'train_samples_per_second': 2.075, 'train_steps_per_second': 0.208, 'train_loss': 2.0237730344136557, 'epoch': 2.4}\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='kaggle/output', \n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    do_eval=False,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=20,\n",
    "    lr_scheduler_type='cosine',\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "dataset = ds.shuffle(seed=42)\n",
    "\n",
    "    # Define the number of folds\n",
    "num_folds = 5\n",
    "fold_size = len(dataset) // num_folds\n",
    "\n",
    "folds = []\n",
    "for i in range(num_folds):\n",
    "    # Calculate start and end indices\n",
    "    start = i * fold_size\n",
    "    end = start + fold_size if i < num_folds - 1 else len(dataset)\n",
    "\n",
    "    # Select data for the fold\n",
    "    fold = dataset.select(range(start, end))\n",
    "    folds.append(fold)\n",
    "# train a different model for 5 different folds of the dataset\n",
    "for i in range(num_folds):\n",
    "    print(f\"Training fold {i}\")\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        TRAIN_MODEL_PATH,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        mps_device = torch.device(\"mps\")\n",
    "        model.to(mps_device)\n",
    "        print(\"Model moved to MPS device.\")\n",
    "    elif torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        print(\"Model moved to CUDA device.\")\n",
    "    else:\n",
    "        print(\"No GPU available, using CPU.\")\n",
    "\n",
    "    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=folds[i],\n",
    "        data_collator=collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=partial(metrics, all_labels=all_labels)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"deberta3base_1024_fold_{i}\")\n",
    "    tokenizer.save_pretrained(f\"deberta3base_1024_fold_{i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "This is a slightly different procedure. We are implementing a weighted voting approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_tokenize(example, tokenizer, max_length):\n",
    "\n",
    "    # rebuild text from tokens\n",
    "    text = []\n",
    "    token_map = []\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n",
    "        text.append(t)\n",
    "        token_map.extend([idx]*len(t))\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            token_map.append(-1)\n",
    "        idx += 1\n",
    "\n",
    "    # actual tokenization\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_length)\n",
    "\n",
    "    return {**tokenized, \"token_map\": token_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\"deberta3base_1024_fold_0\": 2/10, \n",
    "               \"deberta3base_1024_fold_1\": 2/10, \n",
    "               \"deberta3base_1024_fold_2\": 2/10, \n",
    "               \"deberta3base_1024_fold_3\": 2/10, \n",
    "               \"deberta3base_1024_fold_4\": 2/10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble method prediction\n",
    "def ensemble_predict(model_paths, dataset):\n",
    "    all_preds = []\n",
    "\n",
    "    for path, weight in model_paths.items():\n",
    "        model = AutoModelForTokenClassification.from_pretrained(path)\n",
    "\n",
    "        # if torch.backends.mps.is_available():\n",
    "        #     mps_device = torch.device(\"mps\")\n",
    "        #     model.to(mps_device)\n",
    "        #     print(\"Model moved to MPS device.\")\n",
    "        # elif torch.cuda.is_available():\n",
    "        #     model.cuda()\n",
    "        #     print(\"Model moved to CUDA device.\")\n",
    "        # else:\n",
    "        #     print(\"No GPU available, using CPU.\")\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "        collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            \".\",\n",
    "            per_device_eval_batch_size=1,\n",
    "            report_to=\"none\",\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            data_collator=collator,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "        predictions = trainer.predict(dataset).predictions\n",
    "        weighted_predictions = softmax(predictions, axis=-1)\n",
    "        print(type(weighted_predictions))\n",
    "        print(weight)\n",
    "        weighted_predictions = weighted_predictions * weight\n",
    "        all_preds.append(weighted_predictions)\n",
    "\n",
    "    weighted_average_preds = np.sum(all_preds, axis=0) / sum(model_paths.values())\n",
    "\n",
    "    return weighted_average_preds\n",
    "\n",
    "\n",
    "def predict(model, dataset):\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        \".\",\n",
    "        per_device_eval_batch_size=1,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    predictions = trainer.predict(dataset).predictions\n",
    "    weighted_predictions = softmax(predictions, axis=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a66e1337324147a9aab9de232dff5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=3):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoniorevilla/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a123b616c93b4427bf88b3d0231ac89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11871d8c31674dc1a1af8e31d4ec4904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8481762fbd654215bb9a1a34754cbbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0448e7c2eb54450a68e9ac3decfb087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525bbe6666904ddfa9d6ae66a1189b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# TODO: insert test data\n",
    "test_data = json.load(open(\"kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\n",
    "test_frame = pd.DataFrame(test_data)\n",
    "ds_test = Dataset.from_pandas(test_frame)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deberta3base_1024_fold_0\")\n",
    "ds_test = ds_test.map(inference_tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": 2048}, num_proc=3)\n",
    "\n",
    "model_path = \"deberta3base_1024_fold_0\"\n",
    "threshold = 0.99\n",
    "weighted_average_predictions = ensemble_predict(model_paths, ds_test)\n",
    "\n",
    "config = json.load(open(Path(model_path) / \"config.json\"))\n",
    "id2label = config[\"id2label\"]\n",
    "preds = weighted_average_predictions.argmax(-1)\n",
    "preds_without_O = weighted_average_predictions[:,:,:12].argmax(-1)\n",
    "O_preds = weighted_average_predictions[:,:,12]\n",
    "preds_final = np.where(O_preds < threshold, preds_without_O , preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>reflexion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Avril</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  token           label  token_str  row_id\n",
       "0         7      4  B-NAME_STUDENT  reflexion       0\n",
       "1         7      5  B-NAME_STUDENT          -       1\n",
       "2         7      6  I-NAME_STUDENT      Avril       2\n",
       "3         7      7  I-NAME_STUDENT       2021       3\n",
       "4         7      8  I-NAME_STUDENT          -       4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = []\n",
    "document, token, label, token_str = [], [], [], []\n",
    "for p, token_map, offsets, tokens, doc in zip(preds_final, ds_test[\"token_map\"], ds_test[\"offset_mapping\"], ds_test[\"tokens\"], ds_test[\"document\"]):\n",
    "\n",
    "    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "        label_pred = id2label[str(token_pred)]\n",
    "\n",
    "        if start_idx + end_idx == 0: continue\n",
    "\n",
    "        if token_map[start_idx] == -1:\n",
    "            start_idx += 1\n",
    "\n",
    "        # ignore \"\\n\\n\"\n",
    "        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        if start_idx >= len(token_map): break\n",
    "\n",
    "        token_id = token_map[start_idx]\n",
    "\n",
    "        # ignore \"O\" predictions and whitespace preds\n",
    "        if label_pred != \"O\" and token_id != -1:\n",
    "            triplet = (label_pred, token_id, tokens[token_id])\n",
    "\n",
    "            if triplet not in triplets:\n",
    "                document.append(doc)\n",
    "                token.append(token_id)\n",
    "                label.append(label_pred)\n",
    "                token_str.append(tokens[token_id])\n",
    "                triplets.append(triplet)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label,\n",
    "    \"token_str\": token_str\n",
    "})\n",
    "\n",
    "df[\"row_id\"] = list(range(len(df)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-05 01:28:19,921] A new study created in memory with name: no-name-b694bd2c-2ae2-418d-b912-3aaa8c34634d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9b920e91af4674bd3aca79bf3188ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial, model_paths, labels, all_labels, test_data):\n",
    "    # Define the search space for the weights\n",
    "    weights = {}\n",
    "    for model_name in model_paths:\n",
    "        weights[model_name] = trial.suggest_float(model_name, 0.0, 1.0)\n",
    "\n",
    "    # Create the ensemble model using the weights\n",
    "    weighted_models = {model_name: weights[model_name] for model_name in model_paths}\n",
    "\n",
    "    # Generate predictions using the ensemble model\n",
    "    predictions = ensemble_predict(weighted_models, test_data)\n",
    "\n",
    "    # Evaluate the predictions using the evaluation metric\n",
    "    metric_value = metrics((predictions, labels), all_labels)['f5']\n",
    "\n",
    "    return metric_value\n",
    "\n",
    "# Create a study object and optimize the weights\n",
    "data_splits = ds.shuffle(seed=42).train_test_split(test_size=0.1, seed=42)\n",
    "test_data = data_splits[\"test\"]\n",
    "model_names = [\"deberta3base_1024_fold_0\", \"deberta3base_1024_fold_1\", \"deberta3base_1024_fold_2\", \"deberta3base_1024_fold_3\", \"deberta3base_1024_fold_4\"]\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, model_names, test_data['labels'], all_labels, test_data), n_trials=50)\n",
    "\n",
    "# Get the best weights and their corresponding metric value\n",
    "best_weights = study.best_params.items()\n",
    "best_metric = study.best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_items([('deberta3base_1024_fold_0', 0.39622189060869173), ('deberta3base_1024_fold_1', 0.9769709248621039), ('deberta3base_1024_fold_2', 0.592992672873292), ('deberta3base_1024_fold_3', 0.027945723847054293), ('deberta3base_1024_fold_4', 0.23466717979570073)]),\n",
       " 0.9070422535211269)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "# save best_weights and best_metric\n",
    "with open('best_weights.pkl', 'wb') as f:\n",
    "    pickle.dump(best_weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30217d7493e442495bbd5239596d5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ea821dad604e2b9b23f55fb6ba0333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f6953caca845a9938fafaa8c689931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c146e6d6b24208967fe0ceb4a4813f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e46adac2154cc7a17552fdabc25eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8777042599063267,\n",
       " 'recall': 0.8632641123135419,\n",
       " 'f5': 0.8638107110997296}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splits = ds.shuffle(seed=42).train_test_split(test_size=0.1, seed=42)\n",
    "test_data = data_splits[\"test\"]\n",
    "preds = ensemble_predict(model_paths, test_data)\n",
    "metrics((preds, test_data[\"labels\"]), all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "(\"Could not convert 'irusmgwkqg' with type str: tried to convert to int64\", 'Conversion failed for column document with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# take a random sample of 10% of the data in the frame\u001b[39;00m\n\u001b[1;32m      3\u001b[0m test_df \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m preds \u001b[38;5;241m=\u001b[39m ensemble_predict(model_paths, test_ds)\n\u001b[1;32m      6\u001b[0m metrics((preds, test_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]), all_labels)\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/datasets/arrow_dataset.py:861\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    859\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    860\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 861\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    868\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/pyarrow/table.pxi:3874\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_fut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/pyarrow/array.pxi:339\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/pyarrow/array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/USC/CSCI567/PII_group_project/env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: (\"Could not convert 'irusmgwkqg' with type str: tried to convert to int64\", 'Conversion failed for column document with type object')"
     ]
    }
   ],
   "source": [
    "# take a random sample of 10% of the data in ds\n",
    "\n",
    "test_df = data_df.sample(frac=0.1)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "preds = ensemble_predict(model_paths, test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
